{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaNkhdzkT5de"
   },
   "source": [
    "# **Data Analytics and Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDcimOPTL8mF"
   },
   "source": [
    " üßëüèª‚Äçüè´ **Dosen Pengampu :**\n",
    "\n",
    "- Wayan Oger Vihikan, S.T.I., M.I.T.\n",
    "\n",
    "üßëüèª‚Äçüéì **Anggota Kelompok 2 :**\n",
    "\n",
    "- 2105551125 - Anak Agung Sagung Mirah Indira Wardhana\n",
    "\n",
    "- 2105551122 - Mananda Davar Sinaga\n",
    "\n",
    "- 2105551126 - I Nyoman Yodya Mahesa Sastra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwtlzQeiz7vl"
   },
   "source": [
    "# **Scraping Data Website AOTY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FWgbQ4lLWQH"
   },
   "source": [
    "Notebook ini berisi kode untuk scraping website AOTY (Album of the year)\\\n",
    "https://www.albumoftheyear.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV4lVj2azt82"
   },
   "source": [
    "## **Import Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIhsOzKxS_sI"
   },
   "source": [
    "üìö **Library yang digunakan :**\n",
    "\n",
    "- `request`, digunakan untuk melakukan HTTP request ke website albumoftheyear\n",
    "\n",
    "- `pandas`, digunakan untuk manipulasi dan analisis data\n",
    "\n",
    "- `bs4`, digunakan untuk parser HTML\n",
    "\n",
    "- `concurrent.futures`, digunakan untuk multithreading dalam mempercepat scraping web\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fyxP4q32klxt"
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import requests # HTTP request\n",
    "import pandas as pd # Data manipulation & analysis\n",
    "from bs4 import BeautifulSoup # HTML parser\n",
    "from concurrent.futures import ThreadPoolExecutor # Concurrent Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr7CiJPktMfF"
   },
   "source": [
    "## **Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WZEOG-6NB6m"
   },
   "source": [
    "Kami membentuk beberapa function dengan tujuan untuk mempermudah pembacaan program dan juga agar dapat dilakukan multithreading dengan menggunakan `ThreadPoolExecutor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PggvwzNAtQFn"
   },
   "source": [
    "### get_dan_parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEQYksjUTDnJ"
   },
   "source": [
    "üìö **Function `get_dan_parse()`**\\\n",
    "berfungsi untuk melakukan scrape web sekaligus parse HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gOLB-OUJrl1D"
   },
   "outputs": [],
   "source": [
    "# Function untuk GET HTTP Request dan Parsing\n",
    "def get_dan_parse(link: str):\n",
    "  header = {'User-Agent': 'Mozilla/5.0'}\n",
    "  web = requests.get(link, headers=header).content\n",
    "  web_parsed = BeautifulSoup(web, \"html.parser\")\n",
    "\n",
    "  # bs4.BeautifulSoup\n",
    "  return web_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fPxm219tShO"
   },
   "source": [
    "### scraping_top_billboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zM4BDn9TGEB"
   },
   "source": [
    "üìö **Function `scraping_top_billboard()`**\\\n",
    "berfungsi untuk melakukan scrape web pada top 50 album billboard 2023\\\n",
    "https://www.albumoftheyear.org/list/2154-billboards-50-best-albums-of-2023/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty_top50.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzYPMCV5kFiE"
   },
   "outputs": [],
   "source": [
    "# Function untuk scraping top 50 album billboard 2023\n",
    "def scraping_top_billboard(link: str):\n",
    "  web = get_dan_parse(link)\n",
    "  web_albums = web.find_all(class_='albumListTitle')\n",
    "  albums = list()\n",
    "  for album in web_albums:\n",
    "    artisjudul_album = album.text.split('. ', 1)[1].split(' - ', 1) # Angka. NamaArtis - NamaAlbum -> ['NamaArtis', 'NamaAlbum']\n",
    "    # 1. Nama Artis\n",
    "    artis_album = artisjudul_album[0] # NamaArtis\n",
    "    # 2. Nama Album\n",
    "    nama_album = artisjudul_album[1] # NamaAlbum\n",
    "    # 3. Link Album\n",
    "    link_album = 'https://www.albumoftheyear.org' + album.find('a')['href'] # https://www.albumoftheyear.org/album/link_album/\n",
    "    albums.append([artis_album, nama_album, link_album])\n",
    "\n",
    "  # list('artis', 'album', 'link_album')\n",
    "  return albums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0ISGVMWtVVs"
   },
   "source": [
    "### scraping_album_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4bn38ePTMWJ"
   },
   "source": [
    "üìö **Function `scraping_album_review()`**\\\n",
    "berfungsi untuk melakukan scrape 1.000 review terbaik pada masing-masing album\\\n",
    "contoh: https://www.albumoftheyear.org/album/722921-taylor-swift-1989-taylors-version/user-reviews/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty_review.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZL-gO0N6eD7Q"
   },
   "outputs": [],
   "source": [
    "def scraping_album_review(link: str):\n",
    "  # 1. Link Masuk Ke album\n",
    "  url_parent = link.split('/user-reviews')[0]\n",
    "\n",
    "  # Cek apakah ada wildcard '?p='\n",
    "  if '?p=' in link:\n",
    "    web = get_dan_parse(link+'&sort=best')\n",
    "  else:\n",
    "    web = get_dan_parse(link+'/?sort=best')\n",
    "\n",
    "  review_list = list()\n",
    "  web_review = web.find_all(class_='albumReviewRow')\n",
    "  for review in web_review:\n",
    "    # 2. Nama User\n",
    "    nama_user = review.find(class_='userReviewName').text\n",
    "    # 3. Rating\n",
    "    rating = review.find(class_='rating').text\n",
    "    # 4. Link User\n",
    "    link_user = 'https://www.albumoftheyear.org' + review.find(class_='userReviewName').find('a')['href']\n",
    "    review_list.append([url_parent, nama_user, rating, link_user])\n",
    "\n",
    "  if web.find(class_='pageSelect next'):\n",
    "    # Lanjut scrape dan stop jika sudah page 40\n",
    "    nextpage = link.split('?p=')\n",
    "    try:\n",
    "      nextlink = nextpage[0] + '?p=' + str(int(nextpage[1]) + 1)\n",
    "      if len(nextpage) > 1 and nextpage[1] != '40':\n",
    "        review_list.extend(scraping_album_review(nextlink))\n",
    "    except:\n",
    "      nextlink = nextpage[0] + '?p=2'\n",
    "      review_list.extend(scraping_album_review(nextlink))\n",
    "\n",
    "  # list('link_album', 'user', 'rating_album', 'link_user')\n",
    "  return review_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPO8GScmtZaC"
   },
   "source": [
    "### scraping_user_rating()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIct5XnbTPqM"
   },
   "source": [
    "üìö **Function `scraping_user_rating()`**\\\n",
    "berfungsi untuk melakukan scrape 600 album terbaik yang dirating masing-masing user\\\n",
    "contoh: https://www.albumoftheyear.org/user/calup/ratings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty_rating.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oC5HTKs8KpF4"
   },
   "outputs": [],
   "source": [
    "# Function untuk scraping user rating\n",
    "def scraping_user_rating(link: str):\n",
    "  url_parent = link.split('ratings/highest/')\n",
    "\n",
    "  # Cek halaman pertama atau bukan\n",
    "  if len(url_parent) == 1:\n",
    "    link = link + 'ratings/highest/'\n",
    "\n",
    "  review_list = list()\n",
    "\n",
    "  web = get_dan_parse(link)\n",
    "  # 2. Nama User\n",
    "  nama_user = web.find(class_='userLink').text\n",
    "  # 4. Link User\n",
    "  link_user = url_parent[0]\n",
    "\n",
    "  web_review = web.find_all(class_='albumBlock')\n",
    "  for review in web_review:\n",
    "    artis_dan_album = review.find_all('a')\n",
    "    # 1. link masuk ke album\n",
    "    link_album = 'https://www.albumoftheyear.org' + artis_dan_album[0]['href']\n",
    "    # 3. Rating Album\n",
    "    rating_album = review.find(class_='rating').text\n",
    "    review_list.append([link_album, nama_user, rating_album, link_user])\n",
    "\n",
    "  if web.find(class_='pageSelectRow'):\n",
    "    # lanjut scrape dan stop jika sudah page 10\n",
    "    next = web.find(class_='pageSelectRow').find_all(class_='pageSelectSmall')\n",
    "    try:\n",
    "      currentpagenum = int(url_parent[1].split('/')[0])\n",
    "      nextpagenum = currentpagenum + 1\n",
    "      nextlink = url_parent[0] + 'ratings/highest/' + str(nextpagenum) + '/'\n",
    "      if int(next[-1].text) != currentpagenum and currentpagenum < 10:\n",
    "        review_list.extend(scraping_user_rating(nextlink))\n",
    "    except:\n",
    "      nextlink = link + '2/'\n",
    "      review_list.extend(scraping_user_rating(nextlink))\n",
    "\n",
    "  # list('link_album', 'user', 'rating_album', 'link_user')\n",
    "  return review_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VI8TQ_Ttb9t"
   },
   "source": [
    "### scraping_artis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QjEWz2aTR-g"
   },
   "source": [
    "üìö **Function `scraping_artis()`**\\\n",
    "berfungsi untuk melakukan scrape thumbnail artis\\\n",
    "contoh: https://www.albumoftheyear.org/artist/323-taylor-swift/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty_artis.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJTKLnPy9Gfc"
   },
   "outputs": [],
   "source": [
    "# Function untuk scraping artis:\n",
    "def scraping_artis(link: str):\n",
    "  web = get_dan_parse(link)\n",
    "  web_image = web.find(class_='artistImage').find('img')['src']\n",
    "\n",
    "  # bs4.BeautifulSoup\n",
    "  return web_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBCFxeO3td_K"
   },
   "source": [
    "### scraping_album()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wH_BASmtTUKV"
   },
   "source": [
    "üìö **Function `scraping_album()`**\\\n",
    "berfungsi untuk melakukan scrape detail-detail album\\\n",
    "contoh: https://www.albumoftheyear.org/album/722921-taylor-swift-1989-taylors-version.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic_aoty_album.png\" style=\"max-height: 300px; max-width: 600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsA1JSHG_q5l"
   },
   "outputs": [],
   "source": [
    "# Function untuk scraping album\n",
    "def scraping_album(link: str):\n",
    "  web = get_dan_parse(link)\n",
    "\n",
    "  web_headline = web.find(class_='albumHeadline').find('h1')\n",
    "  # 1. Nama Artis\n",
    "  artis_album = web_headline.find(class_='artist').text # NamaArtis\n",
    "  # 2. Link Artis\n",
    "  thumbnail_artis = str()\n",
    "  artis_link = str()\n",
    "  try:\n",
    "    artis_link = 'https://www.albumoftheyear.org' + web_headline.find(class_='artist').find('a')['href'] # https://www.albumoftheyear.org/artist/NamaArtis/)\n",
    "    # 13. Thumbnail Artis\n",
    "    thumbnail_artis = scraping_artis(artis_link)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  # 3. Nama Album\n",
    "  nama_album = web_headline.find(class_='albumTitle').text # NamaAlbum\n",
    "\n",
    "  # 4. Thumbnail Album\n",
    "  thumbnail_album = web.find(class_='albumTopBox cover')\n",
    "  try:\n",
    "    thumbnail_album = thumbnail_album.find('img')['src'] # Link Thumbnail Album\n",
    "  except:\n",
    "    thumbnail_album = \"\"\n",
    "\n",
    "  web_tracklist = web.find(class_='trackListTable')\n",
    "  # 5. Tracklist Album\n",
    "  tracklist = str()\n",
    "  try:\n",
    "    if web_tracklist:\n",
    "      for track in web_tracklist:\n",
    "        nama_lagu = track.find(class_=\"trackTitle\").find('a').text # NamaLagu\n",
    "        tracklist += nama_lagu + \";|\"\n",
    "    if tracklist:\n",
    "      tracklist = tracklist[:-2]\n",
    "  except:\n",
    "    tracklist = \"\"\n",
    "\n",
    "  # 6. Link Review\n",
    "  link_review = link + \"/user-reviews/\"\n",
    "\n",
    "  # 7. Tanggal Rilis\n",
    "  tanggalrilis = \"\"\n",
    "  # 8. Label\n",
    "  label = \"\"\n",
    "  # 9. Genre\n",
    "  genre = \"\"\n",
    "  # 10. Producer\n",
    "  produser = \"\"\n",
    "  # 11. Penulis\n",
    "  penulis = \"\"\n",
    "\n",
    "  try:\n",
    "    web_detail_album = web.find(class_='albumTopBox info').find_all(class_='detailRow')\n",
    "    # TANGGAL RILIS\n",
    "    tanggalrilis = web_detail_album[0].text.split(\" /\")[0]\n",
    "    # LABEL LAGU\n",
    "    label = str()\n",
    "    label_plural = web_detail_album[2].find_all('a', class_=\"\")\n",
    "    for value in label_plural:\n",
    "      label += value.text +';|'\n",
    "    if label:\n",
    "      label = label[:-2]\n",
    "    # GENRE LAGU\n",
    "    genre = str()\n",
    "    genre_plural = web_detail_album[3].find_all('a', class_=\"\")\n",
    "    for value in genre_plural:\n",
    "      genre += value.text +';|'\n",
    "    if genre:\n",
    "      genre = genre[:-2]\n",
    "    # PRODUSER\n",
    "    produser = str()\n",
    "    produser_plural = web_detail_album[4].find_all('a', class_=\"\")\n",
    "    for value in produser_plural:\n",
    "      produser += value.text +';|'\n",
    "    if produser:\n",
    "      produser = produser[:-2]\n",
    "    # PENULIS\n",
    "    penulis = str()\n",
    "    penulis_plural = web_detail_album[5].find_all('a', class_=\"\")\n",
    "    for value in penulis_plural:\n",
    "      penulis += value.text +';|'\n",
    "    if penulis:\n",
    "      penulis = penulis[:-2]\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "  album = [artis_album, artis_link, nama_album, thumbnail_album, tracklist, link_review, tanggalrilis, label, genre, produser, penulis, link, thumbnail_artis]\n",
    "\n",
    "  # list('artis', 'link_artis', 'album', 'thumbnail_album', 'tracklist_album', 'link_review', 'tanggal_rilis', 'label', 'genre', 'produser', 'penulis', 'link_album', 'thumbnail_artis')\n",
    "  return album"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJmU1J49oCqv"
   },
   "source": [
    "## Program Utama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01c5Hm6hTvBf"
   },
   "source": [
    "üìö **Program Utama**\\\n",
    "Berikut merupakan program utama dari scraping AOTY (Album of The Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJY6jgLG-g_7"
   },
   "outputs": [],
   "source": [
    "# Link top 50 album billboard 2023\n",
    "billboard = \"https://www.albumoftheyear.org/list/2154-billboards-50-best-albums-of-2023/\"\n",
    "\n",
    "# Scrape top 50 album billboard 2023\n",
    "albums = scraping_top_billboard(billboard)\n",
    "\n",
    "# Scrape detail masing-masing album top 50 billboard 2023\n",
    "list_link = []\n",
    "for album in albums:\n",
    "  list_link.append(album[2])\n",
    "with ThreadPoolExecutor() as executor:\n",
    "  results_topalbum = list(executor.map(scraping_album, list_link))\n",
    "\n",
    "# Scrape review masing-masing album top 50 billboard 2023\n",
    "list_link = []\n",
    "for result in results_topalbum:\n",
    "  list_link.append(result[5])\n",
    "with ThreadPoolExecutor() as executor:\n",
    "  results_review_topalbum = list(executor.map(scraping_album_review, list_link))\n",
    "\n",
    "# Scrape masing-masing user yang mereview album top 50 billboard 2023\n",
    "list_link = set()\n",
    "for result in results_review_topalbum:\n",
    "  for reviewer in result:\n",
    "    list_link.add(reviewer[3])\n",
    "with ThreadPoolExecutor() as executor:\n",
    "  results_user_rating = list(executor.map(scraping_user_rating, list_link))\n",
    "\n",
    "# Scrape ulang semua detail masing-masing album yang dirating seluruh user\n",
    "list_link = set()\n",
    "for result in results_user_rating:\n",
    "  for album in result:\n",
    "    list_link.add(album[0])\n",
    "with ThreadPoolExecutor() as executor:\n",
    "  results_all_album = list(executor.map(scraping_album, list_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20nLxat1ex4M"
   },
   "outputs": [],
   "source": [
    "# Bentuk data albums menjadi DataFrame\n",
    "dfalbum = pd.DataFrame(results_topalbum, columns=['artis', 'link_artis', 'album', 'thumbnail_album', 'tracklist_album', 'link_review', 'tanggal_rilis', 'label', 'genre', 'produser', 'penulis', 'link_album', 'thumbnail_artis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eo6v2ivOtwfs"
   },
   "outputs": [],
   "source": [
    "# Bentuk data ratings menjadi DataFrame\n",
    "dftemp = []\n",
    "for result in results_review_topalbum:\n",
    "  df = pd.DataFrame(result, columns=['link_album', 'user', 'rating_album', 'link_user'])\n",
    "  dftemp.append(df)\n",
    "dfrating = pd.concat(dftemp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50tEkw_VH8WZ"
   },
   "outputs": [],
   "source": [
    "# Simpan DataFrame albums dan ratings menjadi .csv\n",
    "dfalbum.to_csv('albums.csv', index=False, sep=';', encoding='utf-8')\n",
    "dfrating.to_csv('ratings.csv', index=False, sep=';', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
